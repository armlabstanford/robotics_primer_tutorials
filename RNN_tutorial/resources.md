Useful resources that we've found while preparing for this talk:

## RNN:
- [[Link]](https://www.youtube.com/watch?v=LHXXI4-IEns&feature=youtu.be) Explanatory video on how RNN works

## LSTM:
- [[Link]](https://www.youtube.com/watch?v=8HyCNIVRbSU&feature=youtu.be) Explanatory video on how LSTM works

## Attention:
- [[Link]](https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0) Overview article describing the drawbacks of RNN/LSTM and the emergence of attention-based models.
- [[Link]](https://towardsdatascience.com/attention-in-neural-networks-e66920838742) Attention in Neural Networks
- [[Link]](https://towardsdatascience.com/memory-attention-sequences-37456d271992) Memory, Attention, Sequences

## Transformers:
- [[Link]](https://towardsdatascience.com/transformers-141e32e69591) Transformers
